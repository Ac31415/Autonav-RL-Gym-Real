{"ep_number": 69, "environment": "sim_to_real", "reward_for_ep": -1165.0, "steps": 34, "collision_count": 1, "goal_count": 0}
{"ep_number": 113, "environment": "sim_to_real", "reward_for_ep": 900.0, "steps": 21, "collision_count": 0, "goal_count": 1}
{"ep_number": 189, "environment": "sim_to_real", "reward_for_ep": 820.0, "steps": 37, "collision_count": 0, "goal_count": 1}
{"ep_number": 241, "environment": "sim_to_real", "reward_for_ep": 880.0, "steps": 25, "collision_count": 0, "goal_count": 1}
{"ep_number": 291, "environment": "sim_to_real", "reward_for_ep": 885.0, "steps": 24, "collision_count": 0, "goal_count": 1}
{"ep_number": 345, "environment": "sim_to_real", "reward_for_ep": -1125.0, "steps": 26, "collision_count": 1, "goal_count": 0}
{"ep_number": 387, "environment": "sim_to_real", "reward_for_ep": 905.0, "steps": 20, "collision_count": 0, "goal_count": 1}
{"ep_number": 467, "environment": "sim_to_real", "reward_for_ep": 810.0, "steps": 39, "collision_count": 0, "goal_count": 1}
{"ep_number": 529, "environment": "sim_to_real", "reward_for_ep": 855.0, "steps": 30, "collision_count": 0, "goal_count": 1}
{"ep_number": 617, "environment": "sim_to_real", "reward_for_ep": 790.0, "steps": 43, "collision_count": 0, "goal_count": 1}
{"ep_number": 679, "environment": "sim_to_real", "reward_for_ep": 855.0, "steps": 30, "collision_count": 0, "goal_count": 1}
{"ep_number": 773, "environment": "sim_to_real", "reward_for_ep": 775.0, "steps": 46, "collision_count": 0, "goal_count": 1}
{"ep_number": 827, "environment": "sim_to_real", "reward_for_ep": -1125.0, "steps": 26, "collision_count": 1, "goal_count": 0}
{"ep_number": 887, "environment": "sim_to_real", "reward_for_ep": -1140.0, "steps": 29, "collision_count": 1, "goal_count": 0}
{"ep_number": 995, "environment": "sim_to_real", "reward_for_ep": 740.0, "steps": 53, "collision_count": 0, "goal_count": 1}
{"ep_number": 1067, "environment": "sim_to_real", "reward_for_ep": 830.0, "steps": 35, "collision_count": 0, "goal_count": 1}
{"ep_number": 1133, "environment": "sim_to_real", "reward_for_ep": 845.0, "steps": 32, "collision_count": 0, "goal_count": 1}
{"ep_number": 1219, "environment": "sim_to_real", "reward_for_ep": 795.0, "steps": 42, "collision_count": 0, "goal_count": 1}
{"ep_number": 1297, "environment": "sim_to_real", "reward_for_ep": 815.0, "steps": 38, "collision_count": 0, "goal_count": 1}
{"ep_number": 1377, "environment": "sim_to_real", "reward_for_ep": 810.0, "steps": 39, "collision_count": 0, "goal_count": 1}
