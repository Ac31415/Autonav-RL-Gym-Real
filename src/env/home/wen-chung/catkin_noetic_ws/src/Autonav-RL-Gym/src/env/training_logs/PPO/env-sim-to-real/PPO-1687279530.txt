{"ep_number": 1, "environment": "sim_to_real", "reward_for_ep": -900.0, "steps": 381, "collision_count": true, "goal_count": true}
{"ep_number": 3, "environment": "sim_to_real", "reward_for_ep": -2500.0, "steps": 500, "collision_count": false, "goal_count": false}
{"ep_number": 5, "environment": "sim_to_real", "reward_for_ep": 240.0, "steps": 153, "collision_count": true, "goal_count": true}
{"ep_number": 7, "environment": "sim_to_real", "reward_for_ep": -1735.0, "steps": 148, "collision_count": true, "goal_count": false}
{"ep_number": 9, "environment": "sim_to_real", "reward_for_ep": -2500.0, "steps": 500, "collision_count": false, "goal_count": false}
{"ep_number": 11, "environment": "sim_to_real", "reward_for_ep": -1275.0, "steps": 56, "collision_count": true, "goal_count": false}
{"ep_number": 13, "environment": "sim_to_real", "reward_for_ep": -2500.0, "steps": 500, "collision_count": false, "goal_count": false}
{"ep_number": 15, "environment": "sim_to_real", "reward_for_ep": -1240.0, "steps": 49, "collision_count": true, "goal_count": false}
{"ep_number": 17, "environment": "sim_to_real", "reward_for_ep": 850.0, "steps": 31, "collision_count": true, "goal_count": true}
{"ep_number": 19, "environment": "sim_to_real", "reward_for_ep": -1365.0, "steps": 74, "collision_count": true, "goal_count": false}
{"ep_number": 21, "environment": "sim_to_real", "reward_for_ep": 795.0, "steps": 42, "collision_count": true, "goal_count": true}
{"ep_number": 23, "environment": "sim_to_real", "reward_for_ep": -2500.0, "steps": 500, "collision_count": false, "goal_count": false}
{"ep_number": 25, "environment": "sim_to_real", "reward_for_ep": -1600.0, "steps": 121, "collision_count": true, "goal_count": false}
{"ep_number": 27, "environment": "sim_to_real", "reward_for_ep": 865.0, "steps": 28, "collision_count": true, "goal_count": true}
{"ep_number": 29, "environment": "sim_to_real", "reward_for_ep": -1225.0, "steps": 46, "collision_count": true, "goal_count": false}
{"ep_number": 31, "environment": "sim_to_real", "reward_for_ep": 855.0, "steps": 30, "collision_count": true, "goal_count": true}
{"ep_number": 33, "environment": "sim_to_real", "reward_for_ep": -1205.0, "steps": 42, "collision_count": true, "goal_count": false}
{"ep_number": 35, "environment": "sim_to_real", "reward_for_ep": -1220.0, "steps": 45, "collision_count": true, "goal_count": false}
{"ep_number": 37, "environment": "sim_to_real", "reward_for_ep": 805.0, "steps": 40, "collision_count": true, "goal_count": true}
{"ep_number": 39, "environment": "sim_to_real", "reward_for_ep": -3230.0, "steps": 447, "collision_count": true, "goal_count": false}
{"ep_number": 41, "environment": "sim_to_real", "reward_for_ep": -1300.0, "steps": 61, "collision_count": true, "goal_count": false}
{"ep_number": 43, "environment": "sim_to_real", "reward_for_ep": -3365.0, "steps": 474, "collision_count": true, "goal_count": false}
{"ep_number": 45, "environment": "sim_to_real", "reward_for_ep": -2930.0, "steps": 387, "collision_count": true, "goal_count": false}
{"ep_number": 47, "environment": "sim_to_real", "reward_for_ep": -1285.0, "steps": 58, "collision_count": true, "goal_count": false}
{"ep_number": 49, "environment": "sim_to_real", "reward_for_ep": -1190.0, "steps": 39, "collision_count": true, "goal_count": false}
{"ep_number": 51, "environment": "sim_to_real", "reward_for_ep": -1315.0, "steps": 64, "collision_count": true, "goal_count": false}
{"ep_number": 53, "environment": "sim_to_real", "reward_for_ep": -1675.0, "steps": 136, "collision_count": true, "goal_count": false}
{"ep_number": 55, "environment": "sim_to_real", "reward_for_ep": -1625.0, "steps": 126, "collision_count": true, "goal_count": false}
{"ep_number": 57, "environment": "sim_to_real", "reward_for_ep": -1610.0, "steps": 123, "collision_count": true, "goal_count": false}
{"ep_number": 59, "environment": "sim_to_real", "reward_for_ep": 940.0, "steps": 13, "collision_count": true, "goal_count": true}
{"ep_number": 61, "environment": "sim_to_real", "reward_for_ep": 505.0, "steps": 100, "collision_count": true, "goal_count": true}
{"ep_number": 63, "environment": "sim_to_real", "reward_for_ep": 840.0, "steps": 33, "collision_count": true, "goal_count": true}
{"ep_number": 65, "environment": "sim_to_real", "reward_for_ep": 815.0, "steps": 38, "collision_count": true, "goal_count": true}
{"ep_number": 67, "environment": "sim_to_real", "reward_for_ep": -1595.0, "steps": 120, "collision_count": true, "goal_count": false}
{"ep_number": 69, "environment": "sim_to_real", "reward_for_ep": 660.0, "steps": 69, "collision_count": true, "goal_count": true}
{"ep_number": 71, "environment": "sim_to_real", "reward_for_ep": -1365.0, "steps": 74, "collision_count": true, "goal_count": false}
{"ep_number": 73, "environment": "sim_to_real", "reward_for_ep": -1315.0, "steps": 64, "collision_count": true, "goal_count": false}
{"ep_number": 75, "environment": "sim_to_real", "reward_for_ep": -1430.0, "steps": 87, "collision_count": true, "goal_count": false}
{"ep_number": 77, "environment": "sim_to_real", "reward_for_ep": -1350.0, "steps": 71, "collision_count": true, "goal_count": false}
{"ep_number": 79, "environment": "sim_to_real", "reward_for_ep": -1275.0, "steps": 56, "collision_count": true, "goal_count": false}
{"ep_number": 81, "environment": "sim_to_real", "reward_for_ep": -1605.0, "steps": 122, "collision_count": true, "goal_count": false}
{"ep_number": 83, "environment": "sim_to_real", "reward_for_ep": -1655.0, "steps": 132, "collision_count": true, "goal_count": false}
{"ep_number": 85, "environment": "sim_to_real", "reward_for_ep": 635.0, "steps": 74, "collision_count": true, "goal_count": true}
{"ep_number": 87, "environment": "sim_to_real", "reward_for_ep": 805.0, "steps": 40, "collision_count": true, "goal_count": true}
{"ep_number": 89, "environment": "sim_to_real", "reward_for_ep": -1445.0, "steps": 90, "collision_count": true, "goal_count": false}
{"ep_number": 91, "environment": "sim_to_real", "reward_for_ep": 820.0, "steps": 37, "collision_count": true, "goal_count": true}
{"ep_number": 93, "environment": "sim_to_real", "reward_for_ep": -2255.0, "steps": 252, "collision_count": true, "goal_count": false}
{"ep_number": 95, "environment": "sim_to_real", "reward_for_ep": 875.0, "steps": 26, "collision_count": true, "goal_count": true}
{"ep_number": 97, "environment": "sim_to_real", "reward_for_ep": 315.0, "steps": 138, "collision_count": true, "goal_count": true}
{"ep_number": 99, "environment": "sim_to_real", "reward_for_ep": 295.0, "steps": 142, "collision_count": true, "goal_count": true}
{"ep_number": 101, "environment": "sim_to_real", "reward_for_ep": -1245.0, "steps": 50, "collision_count": true, "goal_count": false}
{"ep_number": 103, "environment": "sim_to_real", "reward_for_ep": -2020.0, "steps": 205, "collision_count": true, "goal_count": false}
{"ep_number": 105, "environment": "sim_to_real", "reward_for_ep": -1685.0, "steps": 138, "collision_count": true, "goal_count": false}
{"ep_number": 107, "environment": "sim_to_real", "reward_for_ep": -2170.0, "steps": 235, "collision_count": true, "goal_count": false}
{"ep_number": 109, "environment": "sim_to_real", "reward_for_ep": -1305.0, "steps": 62, "collision_count": true, "goal_count": false}
{"ep_number": 111, "environment": "sim_to_real", "reward_for_ep": -1320.0, "steps": 65, "collision_count": true, "goal_count": false}
