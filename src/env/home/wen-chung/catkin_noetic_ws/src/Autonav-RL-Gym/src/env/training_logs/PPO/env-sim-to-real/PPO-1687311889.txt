{"ep_number": 1, "environment": "sim_to_real", "reward_for_ep": -1213.0000000000002, "steps": 61, "collision_count": true, "goal_count": false}
{"ep_number": 3, "environment": "sim_to_real", "reward_for_ep": -1397.0, "steps": 47, "collision_count": true, "goal_count": false}
{"ep_number": 5, "environment": "sim_to_real", "reward_for_ep": -1245.0, "steps": 39, "collision_count": true, "goal_count": false}
{"ep_number": 7, "environment": "sim_to_real", "reward_for_ep": -1339.0, "steps": 52, "collision_count": true, "goal_count": false}
{"ep_number": 9, "environment": "sim_to_real", "reward_for_ep": -1472.0000000000002, "steps": 87, "collision_count": true, "goal_count": false}
{"ep_number": 11, "environment": "sim_to_real", "reward_for_ep": -1209.0, "steps": 16, "collision_count": true, "goal_count": false}
{"ep_number": 13, "environment": "sim_to_real", "reward_for_ep": -1185.0, "steps": 30, "collision_count": true, "goal_count": false}
{"ep_number": 15, "environment": "sim_to_real", "reward_for_ep": -1358.0, "steps": 30, "collision_count": true, "goal_count": false}
{"ep_number": 17, "environment": "sim_to_real", "reward_for_ep": -1561.0, "steps": 76, "collision_count": true, "goal_count": false}
{"ep_number": 19, "environment": "sim_to_real", "reward_for_ep": -1507.0, "steps": 58, "collision_count": true, "goal_count": false}
{"ep_number": 21, "environment": "sim_to_real", "reward_for_ep": -1175.0, "steps": 12, "collision_count": true, "goal_count": false}
{"ep_number": 23, "environment": "sim_to_real", "reward_for_ep": -1141.0, "steps": 11, "collision_count": true, "goal_count": false}
{"ep_number": 25, "environment": "sim_to_real", "reward_for_ep": -1253.0, "steps": 42, "collision_count": true, "goal_count": false}
{"ep_number": 27, "environment": "sim_to_real", "reward_for_ep": -1207.0, "steps": 32, "collision_count": true, "goal_count": false}
{"ep_number": 29, "environment": "sim_to_real", "reward_for_ep": -1199.0, "steps": 26, "collision_count": true, "goal_count": false}
{"ep_number": 31, "environment": "sim_to_real", "reward_for_ep": -1603.0, "steps": 98, "collision_count": true, "goal_count": false}
{"ep_number": 33, "environment": "sim_to_real", "reward_for_ep": 892.0, "steps": 22, "collision_count": true, "goal_count": true}
{"ep_number": 35, "environment": "sim_to_real", "reward_for_ep": -1126.0, "steps": 17, "collision_count": true, "goal_count": false}
{"ep_number": 37, "environment": "sim_to_real", "reward_for_ep": -1440.0, "steps": 52, "collision_count": true, "goal_count": false}
{"ep_number": 39, "environment": "sim_to_real", "reward_for_ep": -1281.0, "steps": 35, "collision_count": true, "goal_count": false}
{"ep_number": 41, "environment": "sim_to_real", "reward_for_ep": -1334.0, "steps": 42, "collision_count": true, "goal_count": false}
{"ep_number": 43, "environment": "sim_to_real", "reward_for_ep": -1413.0000000000002, "steps": 64, "collision_count": true, "goal_count": false}
{"ep_number": 45, "environment": "sim_to_real", "reward_for_ep": -1283.0, "steps": 39, "collision_count": true, "goal_count": false}
{"ep_number": 47, "environment": "sim_to_real", "reward_for_ep": -1341.0, "steps": 29, "collision_count": true, "goal_count": false}
{"ep_number": 49, "environment": "sim_to_real", "reward_for_ep": -1206.0, "steps": 55, "collision_count": true, "goal_count": false}
