{"ep_number": 1, "environment": "sim_to_real", "reward_for_ep": -1488.0, "steps": 26, "collision_count": true, "goal_count": false}
{"ep_number": 3, "environment": "sim_to_real", "reward_for_ep": -2526.0, "steps": 143, "collision_count": true, "goal_count": false}
{"ep_number": 5, "environment": "sim_to_real", "reward_for_ep": 791.0, "steps": 15, "collision_count": true, "goal_count": true}
{"ep_number": 7, "environment": "sim_to_real", "reward_for_ep": -1638.0, "steps": 66, "collision_count": true, "goal_count": false}
{"ep_number": 9, "environment": "sim_to_real", "reward_for_ep": -4573.0, "steps": 375, "collision_count": true, "goal_count": false}
{"ep_number": 11, "environment": "sim_to_real", "reward_for_ep": -2675.0, "steps": 164, "collision_count": true, "goal_count": false}
{"ep_number": 13, "environment": "sim_to_real", "reward_for_ep": -3346.0, "steps": 217, "collision_count": true, "goal_count": false}
{"ep_number": 15, "environment": "sim_to_real", "reward_for_ep": -2617.0, "steps": 147, "collision_count": true, "goal_count": false}
{"ep_number": 17, "environment": "sim_to_real", "reward_for_ep": -1662.0, "steps": 57, "collision_count": true, "goal_count": false}
{"ep_number": 19, "environment": "sim_to_real", "reward_for_ep": -2006.0, "steps": 110, "collision_count": true, "goal_count": false}
{"ep_number": 21, "environment": "sim_to_real", "reward_for_ep": -2439.0, "steps": 135, "collision_count": true, "goal_count": false}
{"ep_number": 23, "environment": "sim_to_real", "reward_for_ep": -2935.0, "steps": 173, "collision_count": true, "goal_count": false}
{"ep_number": 25, "environment": "sim_to_real", "reward_for_ep": -3894.0, "steps": 279, "collision_count": true, "goal_count": false}
{"ep_number": 27, "environment": "sim_to_real", "reward_for_ep": -2224.0, "steps": 138, "collision_count": true, "goal_count": false}
{"ep_number": 29, "environment": "sim_to_real", "reward_for_ep": -1436.0, "steps": 29, "collision_count": true, "goal_count": false}
{"ep_number": 31, "environment": "sim_to_real", "reward_for_ep": -2800.0, "steps": 170, "collision_count": true, "goal_count": false}
{"ep_number": 33, "environment": "sim_to_real", "reward_for_ep": -2086.0, "steps": 91, "collision_count": true, "goal_count": false}
{"ep_number": 35, "environment": "sim_to_real", "reward_for_ep": -3222.0, "steps": 230, "collision_count": true, "goal_count": false}
{"ep_number": 37, "environment": "sim_to_real", "reward_for_ep": -3544.0, "steps": 225, "collision_count": true, "goal_count": false}
{"ep_number": 39, "environment": "sim_to_real", "reward_for_ep": -2862.0, "steps": 167, "collision_count": true, "goal_count": false}
{"ep_number": 41, "environment": "sim_to_real", "reward_for_ep": -2691.0, "steps": 150, "collision_count": true, "goal_count": false}
{"ep_number": 43, "environment": "sim_to_real", "reward_for_ep": -1923.0, "steps": 84, "collision_count": true, "goal_count": false}
{"ep_number": 45, "environment": "sim_to_real", "reward_for_ep": -3566.0, "steps": 234, "collision_count": true, "goal_count": false}
{"ep_number": 47, "environment": "sim_to_real", "reward_for_ep": -1841.0, "steps": 65, "collision_count": true, "goal_count": false}
